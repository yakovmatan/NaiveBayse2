
# Naive Bayes Classification Project

This Python project implements a complete Naive Bayes classification system, including data loading, preprocessing, model training, evaluation, REST APIs, and interactive Streamlit apps for prediction and visualization.

---

## ğŸ“¦ Project Structure

```
.
|--â””â”€â”€ data/
    â””â”€â”€ buy_computer_data.csv  
â”œâ”€â”€ the_model/
â”‚   â”œâ”€â”€ data_loader.py          # Load CSV, Excel, JSON data files
â”‚   â”œâ”€â”€ cleaner.py              # Data cleaning (currently a placeholder)
â”‚   â”œâ”€â”€ builder.py              # Naive Bayes model implementation with smoothing
â”‚   â”œâ”€â”€ split_data.py           # Train/test split function
â”‚   â””â”€â”€ valitator.py            # Model evaluation: accuracy, confusion matrix
â”œâ”€â”€ manager.py                  # Workflow manager: data â†’ clean â†’ split â†’ train â†’ eval
â”œâ”€â”€ main.py                     # Main API (port 8000) exposing model stats
â”œâ”€â”€ classifeir/
â”‚   â”œâ”€â”€ prediction.py           # Predict single samples
â”‚   â””â”€â”€ info_model.py           # Load trained model info for prediction API
â”œâ”€â”€ main_prediction.py          # Prediction API (port 8001)
â”œâ”€â”€ app_streamlit.py            # Streamlit app for interactive prediction UI
â”œâ”€â”€ dashboard_streamlit.py      # Streamlit dashboard for model evaluation visualization
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Dockerfile for main API
â”œâ”€â”€ Dockerfile_prediction       # Dockerfile for prediction API
 # Sample dataset
```

---

## âœ¨ Features

- Load datasets in CSV, Excel, or JSON formats  
- Basic data cleaning placeholder for future enhancements  
- Split datasets into training and testing sets  
- Train a Naive Bayes classifier with Laplace smoothing  
- Evaluate model performance: accuracy and confusion matrix  
- RESTful APIs exposing model stats and prediction endpoints  
- Two separate APIs: one for stats (port 8000) and one for prediction (port 8001)  
- Interactive Streamlit apps for easy prediction and visual evaluation  
- Docker support for containerized deployment  

---

## ğŸ› ï¸ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the main API (statistics & model info)

```bash
docker build -t naive-bayes-api -f Dockerfile .
docker run -p 8000:8000 naive-bayes-api
```

The API will be available at: `http://localhost:8000`

### 3. Run the prediction API

```bash
docker build -t naive-bayes-prediction -f Dockerfile_prediction .
docker run -p 8001:8001 naive-bayes-prediction
```

The API will be available at: `http://localhost:8001`

### 4. Run the Streamlit app for prediction UI

```bash
streamlit run app_streamlit.py
```

### 5. Run the Streamlit dashboard for model evaluation

```bash
streamlit run dashboard_streamlit.py
```

---

## ğŸ“š How It Works

1. Load data using `DataLoader`.  
2. Clean data using `Cleaner` (currently no changes, designed for future).  
3. Split data into train/test sets with `split_dataframe`.  
4. Train the Naive Bayes model (`NaiveBayes.fit()`).  
5. Evaluate the model using `Evaluation` class (accuracy, confusion matrix).  
6. Use `NaiveBayesManager` to orchestrate all these steps and serve data via API.  
7. Use main API to get model statistics and metadata.  
8. Use prediction API for single-sample prediction requests.  
9. Streamlit apps consume these APIs for interactive usage.

---

## âš ï¸ Notes

- There is a minor typo in the code: `get_confusion_metrix` should be `get_confusion_matrix`.  
- Enhance `Cleaner` to perform real data preprocessing.  
- Run both APIs simultaneously to enable full Streamlit functionality.  
- Update API URLs and ports in the Streamlit apps as needed.

---

## ğŸ“¦ Dependencies

- pandas  
- scikit-learn  
- fastapi  
- uvicorn  
- requests  
- streamlit  
- seaborn  
- matplotlib  

---

## ğŸ“ Author

Yakov Matan  
GitHub: [https://github.com/yakovmatan](https://github.com/yakovmatan)

---

## ğŸ“œ License

This project is provided for educational purposes. Feel free to use, modify, or extend it.

---

If you have any questions or need further assistance, feel free to ask!
